{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paint Splash!</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>15-Apr-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Application DT 02</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>0+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>14-Mar-17</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fantasy theme dark bw black building</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>1.9M</td>\n",
       "      <td>5,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>20-Mar-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sad Poetry Photo Frames 2018</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>10M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Apr-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anime Manga Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>11M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>19-Jul-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Easy Origami Ideas</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>11M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>6-Jan-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PIP Camera - PIP Collage Maker</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>11M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>29-Nov-17</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Name Art Photo Editor - Focus n Filters</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>12M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boys Photo Editor - Six Pack &amp; Men's Suit</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>12M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>20-Mar-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Popsicle Sticks and Similar DIY Craft Ideas</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>12M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>3-Jan-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>14M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>15-Jan-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logo Maker - Small Business</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>14M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>20-Apr-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Drawing Clothes Fashion Ideas</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>15M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>20-Jul-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>350 Diy Room Decor Ideas</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>17M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>7-Nov-17</td>\n",
       "      <td>2.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>7-Jan-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Smoke Effect Photo Maker - Smoke Editor</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>19M</td>\n",
       "      <td>50,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>26-Apr-18</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Learn To Draw Kawaii Characters</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>2.7M</td>\n",
       "      <td>5,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>6-Jun-18</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>2.8M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>20-Jun-18</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Spring flowers theme couleurs d t space</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>2.9M</td>\n",
       "      <td>100+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>18-Apr-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tattoo Name On My Photo Editor</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>20M</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>2-Apr-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mandala Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>21M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>26-Jun-18</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HD Mickey Minnie Wallpapers</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>23M</td>\n",
       "      <td>50,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>7-Jul-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UNICORN - Color By Number &amp; Pixel Art Coloring</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>24M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Aug-18</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Canva: Poster, banner, card maker &amp; graphic de...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>24M</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sketch - Draw &amp; Paint</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>25M</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>8-Jun-18</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Colorfit - Drawing &amp; Coloring</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>25M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>11-Oct-17</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AJ Styles HD Wallpapers</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>25M</td>\n",
       "      <td>5,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>4-Aug-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Install images with music to make video withou...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>26M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>14-Nov-17</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Text on Photo - Fonteee</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>28M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>27-Oct-17</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Infinite Painter</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>29M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>14-Jun-18</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>Weather Forecast Pro</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>$3.99</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>4-Aug-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>APE Weather ( Live Forecast)</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>9.1M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>3-Jul-18</td>\n",
       "      <td>5.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Wetter by t-online.de</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>9.2M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>14-May-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>AEMET's time</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>9.2M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>17-Jul-17</td>\n",
       "      <td>2.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>weather - weather forecast</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>9.7M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>26-Apr-18</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>The Weather Channel: Rain Forecast &amp; Storm Alerts</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>1-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>AccuWeather: Daily Forecast &amp; Live Weather Rep...</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>6-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>Weather by WeatherBug: Forecast, Radar &amp; Alerts</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>7-Jun-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>MyRadar NOAA Weather Radar</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>4-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>SMHI Weather</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>26-Jun-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>Yahoo Weather</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>1-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>Rainfall radar - weather</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>13-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>Yahoo! Weather for SH Forecast for understandi...</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>The Weather Network</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>6-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>GO Weather - Widget, Theme, Wallpaper, Efficient</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>3-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>Weather From DMI/YR</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>Storm Radar: Tornado Tracker &amp; Hurricane Alerts</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>12-Jun-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>Yandex.Weather</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>23-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>HTC Weather</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>10-Aug-17</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>Weather by eltiempo.es</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10694</th>\n",
       "      <td>Climatempo Lite - 15 day weather forecast</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>15-Jun-18</td>\n",
       "      <td>4.1 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>Weather Live</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>$5.99</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>21-Nov-17</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10696</th>\n",
       "      <td>AccuWeather: Daily Forecast &amp; Live Weather Rep...</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10697</th>\n",
       "      <td>ByssWeather for Wear OS</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>11-Apr-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10698</th>\n",
       "      <td>Weather Data CH</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>500+</td>\n",
       "      <td>$2.99</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>9-Aug-16</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10699</th>\n",
       "      <td>Fu*** Weather (Funny Weather)</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Mature 17+</td>\n",
       "      <td>26-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10700</th>\n",
       "      <td>World Webcams</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>25-Nov-13</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10701</th>\n",
       "      <td>Weather 14 Days</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>18-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10702</th>\n",
       "      <td>Weather by eltiempo.es</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2-Aug-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10703</th>\n",
       "      <td>My Earthquake Alerts - US &amp; Worldwide Earthquakes</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>24-Jul-18</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10704 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App        Category  \\\n",
       "0                                          Paint Splash!  ART_AND_DESIGN   \n",
       "1                                 Test Application DT 02  ART_AND_DESIGN   \n",
       "2                   Fantasy theme dark bw black building  ART_AND_DESIGN   \n",
       "3                           Sad Poetry Photo Frames 2018  ART_AND_DESIGN   \n",
       "4                              Anime Manga Coloring Book  ART_AND_DESIGN   \n",
       "5                                     Easy Origami Ideas  ART_AND_DESIGN   \n",
       "6                         PIP Camera - PIP Collage Maker  ART_AND_DESIGN   \n",
       "7                Name Art Photo Editor - Focus n Filters  ART_AND_DESIGN   \n",
       "8              Boys Photo Editor - Six Pack & Men's Suit  ART_AND_DESIGN   \n",
       "9            Popsicle Sticks and Similar DIY Craft Ideas  ART_AND_DESIGN   \n",
       "10                                   Coloring book moana  ART_AND_DESIGN   \n",
       "11                           Logo Maker - Small Business  ART_AND_DESIGN   \n",
       "12                         Drawing Clothes Fashion Ideas  ART_AND_DESIGN   \n",
       "13                              350 Diy Room Decor Ideas  ART_AND_DESIGN   \n",
       "14        Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN   \n",
       "15               Smoke Effect Photo Maker - Smoke Editor  ART_AND_DESIGN   \n",
       "16                       Learn To Draw Kawaii Characters  ART_AND_DESIGN   \n",
       "17                 Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN   \n",
       "18               Spring flowers theme couleurs d t space  ART_AND_DESIGN   \n",
       "19                        Tattoo Name On My Photo Editor  ART_AND_DESIGN   \n",
       "20                                 Mandala Coloring Book  ART_AND_DESIGN   \n",
       "21                           HD Mickey Minnie Wallpapers  ART_AND_DESIGN   \n",
       "22        UNICORN - Color By Number & Pixel Art Coloring  ART_AND_DESIGN   \n",
       "23     Canva: Poster, banner, card maker & graphic de...  ART_AND_DESIGN   \n",
       "24                                 Sketch - Draw & Paint  ART_AND_DESIGN   \n",
       "25                         Colorfit - Drawing & Coloring  ART_AND_DESIGN   \n",
       "26                               AJ Styles HD Wallpapers  ART_AND_DESIGN   \n",
       "27     Install images with music to make video withou...  ART_AND_DESIGN   \n",
       "28                               Text on Photo - Fonteee  ART_AND_DESIGN   \n",
       "29                                      Infinite Painter  ART_AND_DESIGN   \n",
       "...                                                  ...             ...   \n",
       "10674                               Weather Forecast Pro         WEATHER   \n",
       "10675                       APE Weather ( Live Forecast)         WEATHER   \n",
       "10676                              Wetter by t-online.de         WEATHER   \n",
       "10677                                       AEMET's time         WEATHER   \n",
       "10678                         weather - weather forecast         WEATHER   \n",
       "10679  The Weather Channel: Rain Forecast & Storm Alerts         WEATHER   \n",
       "10680  AccuWeather: Daily Forecast & Live Weather Rep...         WEATHER   \n",
       "10681    Weather by WeatherBug: Forecast, Radar & Alerts         WEATHER   \n",
       "10682                         MyRadar NOAA Weather Radar         WEATHER   \n",
       "10683                                       SMHI Weather         WEATHER   \n",
       "10684                                      Yahoo Weather         WEATHER   \n",
       "10685                           Rainfall radar - weather         WEATHER   \n",
       "10686  Yahoo! Weather for SH Forecast for understandi...         WEATHER   \n",
       "10687                                The Weather Network         WEATHER   \n",
       "10688   GO Weather - Widget, Theme, Wallpaper, Efficient         WEATHER   \n",
       "10689                                Weather From DMI/YR         WEATHER   \n",
       "10690    Storm Radar: Tornado Tracker & Hurricane Alerts         WEATHER   \n",
       "10691                                     Yandex.Weather         WEATHER   \n",
       "10692                                        HTC Weather         WEATHER   \n",
       "10693                             Weather by eltiempo.es         WEATHER   \n",
       "10694          Climatempo Lite - 15 day weather forecast         WEATHER   \n",
       "10695                                       Weather Live         WEATHER   \n",
       "10696  AccuWeather: Daily Forecast & Live Weather Rep...         WEATHER   \n",
       "10697                            ByssWeather for Wear OS         WEATHER   \n",
       "10698                                    Weather Data CH         WEATHER   \n",
       "10699                      Fu*** Weather (Funny Weather)         WEATHER   \n",
       "10700                                      World Webcams         WEATHER   \n",
       "10701                                    Weather 14 Days         WEATHER   \n",
       "10702                             Weather by eltiempo.es         WEATHER   \n",
       "10703  My Earthquake Alerts - US & Worldwide Earthquakes         WEATHER   \n",
       "\n",
       "                     Size     Installs  Price Content Rating Last Updated  \\\n",
       "0                    1.2M     100,000+      0       Everyone    15-Apr-18   \n",
       "1                    1.2M           0+      0       Everyone    14-Mar-17   \n",
       "2                    1.9M       5,000+      0       Everyone    20-Mar-18   \n",
       "3                     10M     100,000+      0       Everyone     2-Apr-18   \n",
       "4                     11M     100,000+      0       Everyone    19-Jul-18   \n",
       "5                     11M     100,000+      0       Everyone     6-Jan-18   \n",
       "6                     11M      10,000+      0       Everyone    29-Nov-17   \n",
       "7                     12M   1,000,000+      0       Everyone    31-Jul-18   \n",
       "8                     12M     100,000+      0       Everyone    20-Mar-18   \n",
       "9                     12M      10,000+      0       Everyone     3-Jan-18   \n",
       "10                    14M     500,000+      0       Everyone    15-Jan-18   \n",
       "11                    14M     100,000+      0       Everyone    20-Apr-18   \n",
       "12                    15M      10,000+      0       Everyone    20-Jul-18   \n",
       "13                    17M      10,000+      0       Everyone     7-Nov-17   \n",
       "14                    19M      10,000+      0       Everyone     7-Jan-18   \n",
       "15                    19M      50,000+      0       Everyone    26-Apr-18   \n",
       "16                   2.7M       5,000+      0       Everyone     6-Jun-18   \n",
       "17                   2.8M     100,000+      0       Everyone    20-Jun-18   \n",
       "18                   2.9M         100+      0       Everyone    18-Apr-18   \n",
       "19                    20M  10,000,000+      0           Teen     2-Apr-18   \n",
       "20                    21M     100,000+      0       Everyone    26-Jun-18   \n",
       "21                    23M      50,000+      0       Everyone     7-Jul-18   \n",
       "22                    24M     500,000+      0       Everyone     2-Aug-18   \n",
       "23                    24M  10,000,000+      0       Everyone    31-Jul-18   \n",
       "24                    25M  50,000,000+      0           Teen     8-Jun-18   \n",
       "25                    25M     500,000+      0       Everyone    11-Oct-17   \n",
       "26                    25M       5,000+      0       Everyone     4-Aug-18   \n",
       "27                    26M     100,000+      0       Everyone    14-Nov-17   \n",
       "28                    28M   1,000,000+      0       Everyone    27-Oct-17   \n",
       "29                    29M   1,000,000+      0       Everyone    14-Jun-18   \n",
       "...                   ...          ...    ...            ...          ...   \n",
       "10674                8.7M     100,000+  $3.99       Everyone     4-Aug-18   \n",
       "10675                9.1M   5,000,000+      0       Everyone     3-Jul-18   \n",
       "10676                9.2M   1,000,000+      0       Everyone    14-May-18   \n",
       "10677                9.2M   1,000,000+      0       Everyone    17-Jul-17   \n",
       "10678                9.7M   1,000,000+      0       Everyone    26-Apr-18   \n",
       "10679  Varies with device  50,000,000+      0       Everyone     1-Aug-18   \n",
       "10680  Varies with device  50,000,000+      0       Everyone     6-Aug-18   \n",
       "10681  Varies with device  10,000,000+      0       Everyone     7-Jun-18   \n",
       "10682  Varies with device  10,000,000+      0       Everyone     4-Aug-18   \n",
       "10683  Varies with device   1,000,000+      0       Everyone    26-Jun-18   \n",
       "10684  Varies with device  10,000,000+      0       Everyone     1-Aug-18   \n",
       "10685  Varies with device   5,000,000+      0       Everyone    13-Jul-18   \n",
       "10686  Varies with device   1,000,000+      0       Everyone     2-Aug-18   \n",
       "10687  Varies with device   5,000,000+      0       Everyone     6-Aug-18   \n",
       "10688  Varies with device  50,000,000+      0       Everyone     3-Aug-18   \n",
       "10689  Varies with device     100,000+      0       Everyone    31-Jul-18   \n",
       "10690  Varies with device   1,000,000+      0       Everyone    12-Jun-18   \n",
       "10691  Varies with device  10,000,000+      0       Everyone    23-Jul-18   \n",
       "10692  Varies with device  10,000,000+      0       Everyone    10-Aug-17   \n",
       "10693  Varies with device   5,000,000+      0       Everyone     2-Aug-18   \n",
       "10694  Varies with device     100,000+      0       Everyone    15-Jun-18   \n",
       "10695  Varies with device     500,000+  $5.99       Everyone    21-Nov-17   \n",
       "10696  Varies with device  50,000,000+      0       Everyone     2-Aug-18   \n",
       "10697  Varies with device   1,000,000+      0       Everyone    11-Apr-18   \n",
       "10698  Varies with device         500+  $2.99       Everyone     9-Aug-16   \n",
       "10699  Varies with device   1,000,000+      0     Mature 17+    26-Jul-18   \n",
       "10700  Varies with device   1,000,000+      0       Everyone    25-Nov-13   \n",
       "10701  Varies with device  10,000,000+      0       Everyone    18-Jul-18   \n",
       "10702  Varies with device   5,000,000+      0       Everyone     2-Aug-18   \n",
       "10703  Varies with device     100,000+      0       Everyone    24-Jul-18   \n",
       "\n",
       "              Android Ver  \n",
       "0              4.1 and up  \n",
       "1              4.2 and up  \n",
       "2              4.0 and up  \n",
       "3            4.0.3 and up  \n",
       "4              4.0 and up  \n",
       "5              4.1 and up  \n",
       "6            4.0.3 and up  \n",
       "7              4.0 and up  \n",
       "8            4.0.3 and up  \n",
       "9              4.1 and up  \n",
       "10           4.0.3 and up  \n",
       "11             4.1 and up  \n",
       "12           4.0.3 and up  \n",
       "13             2.3 and up  \n",
       "14           4.0.3 and up  \n",
       "15           4.0.3 and up  \n",
       "16             4.2 and up  \n",
       "17             4.4 and up  \n",
       "18             4.0 and up  \n",
       "19             4.1 and up  \n",
       "20             4.4 and up  \n",
       "21             4.1 and up  \n",
       "22             4.4 and up  \n",
       "23             4.1 and up  \n",
       "24             4.2 and up  \n",
       "25           4.0.3 and up  \n",
       "26             4.1 and up  \n",
       "27             4.1 and up  \n",
       "28             4.1 and up  \n",
       "29             4.2 and up  \n",
       "...                   ...  \n",
       "10674          4.0 and up  \n",
       "10675          5.0 and up  \n",
       "10676          4.1 and up  \n",
       "10677          2.3 and up  \n",
       "10678          4.0 and up  \n",
       "10679  Varies with device  \n",
       "10680  Varies with device  \n",
       "10681  Varies with device  \n",
       "10682  Varies with device  \n",
       "10683  Varies with device  \n",
       "10684  Varies with device  \n",
       "10685  Varies with device  \n",
       "10686  Varies with device  \n",
       "10687  Varies with device  \n",
       "10688  Varies with device  \n",
       "10689  Varies with device  \n",
       "10690  Varies with device  \n",
       "10691  Varies with device  \n",
       "10692          4.4 and up  \n",
       "10693  Varies with device  \n",
       "10694          4.1 and up  \n",
       "10695  Varies with device  \n",
       "10696  Varies with device  \n",
       "10697  Varies with device  \n",
       "10698  Varies with device  \n",
       "10699  Varies with device  \n",
       "10700  Varies with device  \n",
       "10701  Varies with device  \n",
       "10702  Varies with device  \n",
       "10703  Varies with device  \n",
       "\n",
       "[10704 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('googleplaystore_preprocess.csv')\n",
    "data\n",
    "# data.to_csv('data.csv', sep=\",\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ART_AND_DESIGN', 'AUTO_AND_VEHICLES', 'BEAUTY',\n",
       "       'BOOKS_AND_REFERENCE', 'BUSINESS', 'COMICS', 'COMMUNICATION',\n",
       "       'DATING', 'EDUCATION', 'ENTERTAINMENT', 'EVENTS', 'FAMILY',\n",
       "       'FINANCE', 'FOOD_AND_DRINK', 'GAME', 'HEALTH_AND_FITNESS',\n",
       "       'HOUSE_AND_HOME', 'LIBRARIES_AND_DEMO', 'LIFESTYLE',\n",
       "       'MAPS_AND_NAVIGATION', 'MEDICAL', 'NEWS_AND_MAGAZINES',\n",
       "       'PARENTING', 'PERSONALIZATION', 'PHOTOGRAPHY', 'PRODUCTIVITY',\n",
       "       'SHOPPING', 'SOCIAL', 'SPORTS', 'TOOLS', 'TRAVEL_AND_LOCAL',\n",
       "       'VIDEO_PLAYERS', 'WEATHER'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "newCategory = le.fit_transform(data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.2M', '1.9M', '10M', '11M', '12M', '14M', '15M', '17M', '19M',\n",
       "       '2.7M', '2.8M', '2.9M', '20M', '21M', '23M', '24M', '25M', '26M',\n",
       "       '28M', '29M', '3.1M', '3.5M', '3.6M', '3.7M', '31M', '33M', '37M',\n",
       "       '39M', '4.2M', '4.4M', '4.5M', '4.6M', '5.2M', '5.5M', '5.6M',\n",
       "       '5.9M', '6.0M', '6.1M', '7.0M', '7.7M', '7.9M', '8.0M', '8.2M',\n",
       "       '8.6M', '8.7M', '9.2M', '9.4M', 'Varies with device', '1.1M',\n",
       "       '1.7M', '13M', '16M', '18M', '2.2M', '2.4M', '2.5M', '201k', '27M',\n",
       "       '3.4M', '3.9M', '32M', '34M', '35M', '38M', '4.8M', '42M', '48M',\n",
       "       '5.4M', '5.7M', '54M', '56M', '57M', '58M', '6.3M', '6.5M', '6.6M',\n",
       "       '66M', '8.4M', '8.9M', '885k', '88M', '9.0M', '97M', '2.6M', '22M',\n",
       "       '3.2M', '30M', '52M', '6.4M', '6.7M', '7.1M', '7.4M', '9.8M',\n",
       "       '9.9M', '1.4M', '1.5M', '1.6M', '2.1M', '2.3M', '3.0M', '3.3M',\n",
       "       '4.0M', '4.1M', '4.3M', '4.7M', '4.9M', '41M', '44M', '45M', '49M',\n",
       "       '5.0M', '5.1M', '5.3M', '50M', '51M', '6.8M', '6.9M', '608k',\n",
       "       '619k', '658k', '67M', '688k', '68M', '7.2M', '7.3M', '7.8M',\n",
       "       '73M', '754k', '8.5M', '8.8M', '85M', '87M', '9.1M', '9.3M',\n",
       "       '9.5M', '9.7M', '93k', '942k', '970k', '1.3M', '1.8M', '10.0M',\n",
       "       '2.0M', '23k', '3.8M', '36M', '39k', '46M', '47M', '48k', '498k',\n",
       "       '5.8M', '518k', '51k', '55M', '642k', '7.5M', '7.6M', '74M',\n",
       "       '8.1M', '8.3M', '9.6M', '921k', '92M', '93M', '948k', '96M',\n",
       "       '976k', '98M', '40M', '444k', '6.2M', '609k', '1.0M', '118k',\n",
       "       '172k', '17k', '193k', '20k', '219k', '253k', '269k', '308k',\n",
       "       '323k', '351k', '420k', '437k', '516k', '53M', '598k', '600k',\n",
       "       '61k', '61M', '683k', '695k', '716k', '72k', '780k', '79k', '837k',\n",
       "       '892k', '957k', '961k', '18k', '63M', '70M', '77M', '526k', '556k',\n",
       "       '59M', '76M', '84M', '43M', '72M', '78M', '334k', '100M', '1020k',\n",
       "       '14k', '154k', '157k', '196k', '209k', '222k', '246k', '266k',\n",
       "       '306k', '318k', '44k', '470k', '549k', '552k', '554k', '569k',\n",
       "       '592k', '60M', '629k', '62M', '64M', '655k', '65M', '69M', '705k',\n",
       "       '717k', '71M', '75M', '772k', '787k', '79M', '80M', '818k', '81M',\n",
       "       '82M', '83M', '840k', '842k', '865k', '86M', '874k', '89M', '90M',\n",
       "       '914k', '91M', '930k', '94M', '95M', '981k', '99M', '206k', '400k',\n",
       "       '70k', '775k', '954k', '965k', '116k', '643k', '691k', '226k',\n",
       "       '371k', '613k', '913k', '992k', '656k', '11k', '192k', '200k',\n",
       "       '232k', '292k', '335k', '412k', '414k', '417k', '41k', '429k',\n",
       "       '430k', '442k', '459k', '460k', '478k', '496k', '506k', '624k',\n",
       "       '721k', '728k', '743k', '782k', '8.5k', '812k', '816k', '860k',\n",
       "       '121k', '475k', '499k', '601k', '746k', '74k', '872k', '904k',\n",
       "       '939k', '164k', '676k', '749k', '375k', '378k', '704k', '714k',\n",
       "       '801k', '862k', '887k', '899k', '902k', '924k', '975k', '97k',\n",
       "       '980k', '280k', '28k', '173k', '234k', '238k', '240k', '24k',\n",
       "       '257k', '259k', '26k', '27k', '288k', '309k', '313k', '376k',\n",
       "       '404k', '485k', '500k', '511k', '779k', '853k', '857k', '861k',\n",
       "       '89k', '920k', '951k', '963k', '58k', '663k', '108k', '161k',\n",
       "       '175k', '220k', '293k', '34k', '473k', '50k', '540k', '545k',\n",
       "       '562k', '713k', '720k', '756k', '879k', '169k', '243k', '45k',\n",
       "       '785k', '78k', '847k', '994k', '454k', '458k', '881k', '329k',\n",
       "       '353k', '903k', '103k', '122k', '141k', '143k', '144k', '160k',\n",
       "       '170k', '176k', '190k', '191k', '203k', '208k', '210k', '221k',\n",
       "       '228k', '237k', '241k', '251k', '25k', '270k', '283k', '29k',\n",
       "       '314k', '317k', '319k', '33k', '350k', '364k', '373k', '383k',\n",
       "       '387k', '411k', '421k', '467k', '514k', '523k', '525k', '544k',\n",
       "       '54k', '551k', '55k', '585k', '597k', '626k', '636k', '647k',\n",
       "       '67k', '696k', '730k', '73k', '778k', '784k', '809k', '811k',\n",
       "       '81k', '82k', '898k', '916k', '91k', '940k', '953k', '982k',\n",
       "       '986k', '245k', '186k', '239k', '322k', '582k'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4021\n",
      "5007\n",
      "1676\n"
     ]
    }
   ],
   "source": [
    "# 0<=10M；1<=100M；2為Varies with device\n",
    "newSize = []\n",
    "for i in range(len(data['Size'])):\n",
    "    if data['Size'][i][-1] == 'M':\n",
    "        if float(data['Size'][i][0:-1]) <= 10:\n",
    "            newSize.append(0)\n",
    "        elif float(data['Size'][i][0:-1]) <= 100:\n",
    "            newSize.append(1)\n",
    "    elif data['Size'][i][-1] == 'k':\n",
    "        newSize.append(0)\n",
    "    elif data['Size'][i][-1] == 'e':\n",
    "        newSize.append(2)\n",
    "print(newSize.count(0))\n",
    "print(newSize.count(1))\n",
    "print(newSize.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100,000+', '0+', '5,000+', '10,000+', '1,000,000+', '500,000+',\n",
       "       '50,000+', '100+', '10,000,000+', '50,000,000+', '1,000+',\n",
       "       '5,000,000+', '10+', '50+', '500+', '5+', '1+', '100,000,000+',\n",
       "       '1,000,000,000+', '500,000,000+', '0'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Installs'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197\n",
      "3707\n",
      "2800\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "newInstall = []\n",
    "r = '[’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+' #要去除的符號\n",
    "for i in range(len(data['Installs'])):\n",
    "    temp = int(re.sub(r, \"\", data['Installs'][i]))#去除符號\n",
    "    if temp <= 10000:\n",
    "        newInstall.append(0)\n",
    "    elif temp <= 1000000:\n",
    "        newInstall.append(1)\n",
    "    else:\n",
    "        newInstall.append(2)\n",
    "print(newInstall.count(0))\n",
    "print(newInstall.count(1))\n",
    "print(newInstall.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '$1.99', '$1.49', '$9.99', '$3.08', '$1.96', '$4.49', '$5.99',\n",
       "       '$5.49', '$6.49', '$2.99', '$0.99', '$3.61', '$4.60', '$3.99',\n",
       "       '$1.75', '$89.99', '$2.49', '$19.90', '$17.99', '$4.99', '$8.99',\n",
       "       '$12.99', '$2.90', '$19.99', '$7.99', '$6.99', '$109.99', '$10.00',\n",
       "       '$13.99', '$2.00', '$399.99', '$1.04', '$39.99', '$14.99', '$1.26',\n",
       "       '$4.84', '$389.99', '$19.40', '$1.59', '$46.99', '$1.20', '$4.77',\n",
       "       '$29.99', '$7.49', '$394.99', '$28.99', '$18.99', '$30.99',\n",
       "       '$3.49', '$16.99', '$1.61', '$14.00', '$3.04', '$37.99', '$299.99',\n",
       "       '$379.99', '$400.00', '$11.99', '$15.99', '$9.00', '$1.50',\n",
       "       '$1.00', '$15.46', '$24.99', '$10.99', '$74.99', '$200.00',\n",
       "       '$79.99', '$33.99', '$5.00', '$4.59', '$4.85', '$1.70', '$3.95',\n",
       "       '$1.29', '$2.60', '$4.29', '$8.49', '$154.99', '$3.02', '$3.88',\n",
       "       '$4.80', '$25.99', '$2.59', '$3.28', '$1.76', '$1.97', '$2.50',\n",
       "       '$3.90', '$2.95', '$2.56'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9917\n",
      "787\n"
     ]
    }
   ],
   "source": [
    "# 0:0；1=the other\n",
    "newPrice = []\n",
    "r2 = '[’!\"#$%&\\'()*+,-/:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+' #要去除的符號\n",
    "for i in range(len(data['Price'])):\n",
    "    temp = int(re.sub(r2, \"\", data['Price'][i]))#去除符號\n",
    "    if temp == 0:\n",
    "        newPrice.append(0)\n",
    "    else:\n",
    "        newPrice.append(1)\n",
    "print(newPrice.count(0))\n",
    "print(newPrice.count(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Everyone', 'Teen', 'Everyone 10+', 'Mature 17+',\n",
       "       'Adults only 18+', 'Unrated'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Content Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "newRate = le.fit_transform(data['Content Rating'])\n",
    "print(newRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7256\n",
      "1839\n",
      "1609\n"
     ]
    }
   ],
   "source": [
    "newDate = []\n",
    "for i in data['Last Updated']:\n",
    "    if int(i[-2:]) == 18:\n",
    "        newDate.append(0)\n",
    "    elif int(i[-2:]) == 17:\n",
    "        newDate.append(1)\n",
    "    else:\n",
    "        newDate.append(2)\n",
    "print(newDate.count(0))\n",
    "print(newDate.count(1))\n",
    "print(newDate.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4.1 and up', '4.2 and up', '4.0 and up', '4.0.3 and up',\n",
       "       '2.3 and up', '4.4 and up', '3.0 and up', '5.0 and up',\n",
       "       '2.3.3 and up', 'Varies with device', '6.0 and up', '2.2 and up',\n",
       "       '3.2 and up', '4.4W and up', '4.3 and up', '1.6 and up',\n",
       "       '2.1 and up', '1.0 and up', '5.1 and up', '1.5 and up',\n",
       "       '7.0 and up', '2.0 and up', '5.0 - 7.1.1', '4.0.3 - 7.1.1',\n",
       "       '2.0.1 and up', '3.1 and up', '2.2 - 7.1.1', '8.0 and up',\n",
       "       '7.1 and up', '7.0 - 7.1.1', '5.0 - 6.0', '5.0 - 8.0',\n",
       "       '4.1 - 7.1.1'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Android Ver'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477\n",
      "7154\n",
      "724\n",
      "1349\n"
     ]
    }
   ],
   "source": [
    "newVer = []\n",
    "dic = {}\n",
    "for i in data['Android Ver']:\n",
    "    if i[0] == 'V':\n",
    "        newVer.append(3)\n",
    "    elif i[0] == '1' or i[0] == '2':\n",
    "        newVer.append(0)\n",
    "    elif i[0] == '3' or i[0] == '4':\n",
    "        newVer.append(1)\n",
    "    elif i[0] == '5' or i[0] == '6' or i[0] == '7' or i[0] == '8':\n",
    "        newVer.append(2)\n",
    "print(newVer.count(0))\n",
    "print(newVer.count(1))\n",
    "print(newVer.count(2))\n",
    "print(newVer.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(newCategory,newSize,newInstall,newPrice,newRate,newDate,newVer)),columns = ['Category', 'Size', 'install', 'price', 'rate', 'date', 'ver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('afterpreprocessing.csv',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['install']\n",
    "X = df.drop(columns=['install'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10704\n",
      "10704\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[0])\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = preprocessing.MinMaxScaler()\n",
    "X = pd.DataFrame(scale.fit_transform(X),columns=X.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='rbf')\n",
    "\n",
    "#Gaussian NB model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "#Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=None,criterion='entropy')\n",
    "\n",
    "#Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=None, criterion='entropy')\n",
    "\n",
    "#XGBoost model\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[584 190  26]\n",
      " [362 319 108]\n",
      " [ 85 219 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.73      0.64       800\n",
      "           1       0.44      0.40      0.42       789\n",
      "           2       0.65      0.45      0.53       552\n",
      "\n",
      "    accuracy                           0.54      2141\n",
      "   macro avg       0.55      0.53      0.53      2141\n",
      "weighted avg       0.54      0.54      0.53      2141\n",
      "\n",
      "Original on SVM\n"
     ]
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Original on SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350  21 429]\n",
      " [188  24 577]\n",
      " [ 30  13 509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.44      0.51       800\n",
      "           1       0.41      0.03      0.06       789\n",
      "           2       0.34      0.92      0.49       552\n",
      "\n",
      "    accuracy                           0.41      2141\n",
      "   macro avg       0.46      0.46      0.35      2141\n",
      "weighted avg       0.47      0.41      0.34      2141\n",
      "\n",
      "Original on NB\n"
     ]
    }
   ],
   "source": [
    "clf_gnb.fit(X_train, y_train)\n",
    "y_pred = clf_gnb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Original on NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574 193  33]\n",
      " [324 340 125]\n",
      " [ 85 154 313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.72      0.64       800\n",
      "           1       0.49      0.43      0.46       789\n",
      "           2       0.66      0.57      0.61       552\n",
      "\n",
      "    accuracy                           0.57      2141\n",
      "   macro avg       0.58      0.57      0.57      2141\n",
      "weighted avg       0.57      0.57      0.57      2141\n",
      "\n",
      "Original on D-tree\n"
     ]
    }
   ],
   "source": [
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# dot_data = tree.export_graphviz(dtree, out_file=None, filled=True, rounded=True, special_characters=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "# graph.write_pdf('dtree_image.pdf')\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Original on D-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[572 196  32]\n",
      " [315 341 133]\n",
      " [ 77 155 320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65       800\n",
      "           1       0.49      0.43      0.46       789\n",
      "           2       0.66      0.58      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.57      0.58      0.57      2141\n",
      "\n",
      "Original on Random Forest\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Original on Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574 194  32]\n",
      " [308 354 127]\n",
      " [ 75 152 325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       800\n",
      "           1       0.51      0.45      0.48       789\n",
      "           2       0.67      0.59      0.63       552\n",
      "\n",
      "    accuracy                           0.59      2141\n",
      "   macro avg       0.59      0.58      0.59      2141\n",
      "weighted avg       0.58      0.59      0.58      2141\n",
      "\n",
      "Original on XGBoost\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Original on XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 661,763\n",
      "Trainable params: 661,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6850 samples, validate on 1713 samples\n",
      "Epoch 1/10\n",
      "6850/6850 [==============================] - 2s 352us/step - loss: 0.9485 - accuracy: 0.5076 - val_loss: 0.9479 - val_accuracy: 0.5312\n",
      "Epoch 2/10\n",
      "6850/6850 [==============================] - 2s 266us/step - loss: 0.9287 - accuracy: 0.5200 - val_loss: 0.9178 - val_accuracy: 0.5382\n",
      "Epoch 3/10\n",
      "6850/6850 [==============================] - 2s 271us/step - loss: 0.9226 - accuracy: 0.5241 - val_loss: 0.9188 - val_accuracy: 0.5330\n",
      "Epoch 4/10\n",
      "6850/6850 [==============================] - 2s 266us/step - loss: 0.9161 - accuracy: 0.5260 - val_loss: 0.9199 - val_accuracy: 0.5540\n",
      "Epoch 5/10\n",
      "6850/6850 [==============================] - 2s 266us/step - loss: 0.9169 - accuracy: 0.5253 - val_loss: 0.9090 - val_accuracy: 0.5581\n",
      "Epoch 6/10\n",
      "6850/6850 [==============================] - 2s 277us/step - loss: 0.9080 - accuracy: 0.5330 - val_loss: 0.9088 - val_accuracy: 0.5406\n",
      "Epoch 7/10\n",
      "6850/6850 [==============================] - 2s 278us/step - loss: 0.9087 - accuracy: 0.5378 - val_loss: 0.9115 - val_accuracy: 0.5522\n",
      "Epoch 8/10\n",
      "6850/6850 [==============================] - 2s 267us/step - loss: 0.9071 - accuracy: 0.5393 - val_loss: 0.9212 - val_accuracy: 0.5528\n",
      "Epoch 9/10\n",
      "6850/6850 [==============================] - 2s 274us/step - loss: 0.9075 - accuracy: 0.5377 - val_loss: 0.9014 - val_accuracy: 0.5458\n",
      "Epoch 10/10\n",
      "6850/6850 [==============================] - 2s 279us/step - loss: 0.9007 - accuracy: 0.5464 - val_loss: 0.9230 - val_accuracy: 0.5692\n",
      "2141/2141 [==============================] - 0s 96us/step\n",
      "test loss: 0.9389025353483372\n",
      "test accuracy: 0.5310602784156799\n"
     ]
    }
   ],
   "source": [
    "lbl_train = y_train\n",
    "lbl_test = y_test\n",
    "#DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding \n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=6, kernel_initializer='normal', activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=512, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1024, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# Add output layer\n",
    "model.add(Dense(units=3, kernel_initializer='normal', activation='softmax'))\n",
    "print(model.summary())\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "y_train = np_utils.to_categorical(y_train) \n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665 116  19]\n",
      " [462 226 101]\n",
      " [153 153 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.83      0.64       800\n",
      "           1       0.46      0.29      0.35       789\n",
      "           2       0.67      0.45      0.54       552\n",
      "\n",
      "    accuracy                           0.53      2141\n",
      "   macro avg       0.55      0.52      0.51      2141\n",
      "weighted avg       0.54      0.53      0.51      2141\n",
      "\n",
      "Original on DNN\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(confusion_matrix(lbl_test,y_pred))\n",
    "print(classification_report(lbl_test,y_pred))\n",
    "print('Original on DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[605 181  14]\n",
      " [411 302  76]\n",
      " [107 243 202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63       800\n",
      "           1       0.42      0.38      0.40       789\n",
      "           2       0.69      0.37      0.48       552\n",
      "\n",
      "    accuracy                           0.52      2141\n",
      "   macro avg       0.55      0.50      0.50      2141\n",
      "weighted avg       0.53      0.52      0.51      2141\n",
      "\n",
      "after PCA on SVM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "newX1 = pca.fit_transform(X)\n",
    "X_train2, X_test2, y_train2, y_test2= train_test_split(newX1, y, test_size=0.2, random_state=42)\n",
    "\n",
    "SVM.fit(X_train2, y_train2)\n",
    "y_pred2 = SVM.predict(X_test2)\n",
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print('after PCA on SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[593 161  46]\n",
      " [399 258 132]\n",
      " [109 203 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.62       800\n",
      "           1       0.41      0.33      0.37       789\n",
      "           2       0.57      0.43      0.49       552\n",
      "\n",
      "    accuracy                           0.51      2141\n",
      "   macro avg       0.51      0.50      0.49      2141\n",
      "weighted avg       0.50      0.51      0.50      2141\n",
      "\n",
      "after PCA on NB\n"
     ]
    }
   ],
   "source": [
    "clf_gnb.fit(X_train2, y_train2)\n",
    "y_pred2 = clf_gnb.predict(X_test2)\n",
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print('after PCA on NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570 197  33]\n",
      " [325 336 128]\n",
      " [ 80 155 317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64       800\n",
      "           1       0.49      0.43      0.45       789\n",
      "           2       0.66      0.57      0.62       552\n",
      "\n",
      "    accuracy                           0.57      2141\n",
      "   macro avg       0.58      0.57      0.57      2141\n",
      "weighted avg       0.57      0.57      0.57      2141\n",
      "\n",
      "after PCA on D-tree\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(X_train2, y_train2)\n",
    "y_pred2 = dtree.predict(X_test2)\n",
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print('after PCA on D-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[562 199  39]\n",
      " [308 349 132]\n",
      " [ 74 154 324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.64       800\n",
      "           1       0.50      0.44      0.47       789\n",
      "           2       0.65      0.59      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.57      0.58      0.57      2141\n",
      "\n",
      "after PCA Random Forest\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train2, y_train2)\n",
    "y_pred2 = rf.predict(X_test2)\n",
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print('after PCA Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[577 183  40]\n",
      " [315 336 138]\n",
      " [ 74 153 325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       800\n",
      "           1       0.50      0.43      0.46       789\n",
      "           2       0.65      0.59      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.57      0.58      0.57      2141\n",
      "\n",
      "after PCA on XGBoost\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train2, y_train2)\n",
    "y_pred2 = xgb.predict(X_test2)\n",
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print('after PCA on XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 660,995\n",
      "Trainable params: 660,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6850 samples, validate on 1713 samples\n",
      "Epoch 1/10\n",
      "6850/6850 [==============================] - 2s 346us/step - loss: 0.9660 - accuracy: 0.5146 - val_loss: 0.9461 - val_accuracy: 0.5225\n",
      "Epoch 2/10\n",
      "6850/6850 [==============================] - 2s 281us/step - loss: 0.9556 - accuracy: 0.5174 - val_loss: 0.9491 - val_accuracy: 0.5324\n",
      "Epoch 3/10\n",
      "6850/6850 [==============================] - 2s 287us/step - loss: 0.9465 - accuracy: 0.5145 - val_loss: 0.9325 - val_accuracy: 0.5382\n",
      "Epoch 4/10\n",
      "6850/6850 [==============================] - 2s 296us/step - loss: 0.9386 - accuracy: 0.5218 - val_loss: 0.9422 - val_accuracy: 0.5353\n",
      "Epoch 5/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9396 - accuracy: 0.5184 - val_loss: 0.9435 - val_accuracy: 0.5254\n",
      "Epoch 6/10\n",
      "6850/6850 [==============================] - 2s 280us/step - loss: 0.9342 - accuracy: 0.5222 - val_loss: 0.9278 - val_accuracy: 0.5470\n",
      "Epoch 7/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9282 - accuracy: 0.5244 - val_loss: 0.9279 - val_accuracy: 0.5260\n",
      "Epoch 8/10\n",
      "6850/6850 [==============================] - 2s 290us/step - loss: 0.9308 - accuracy: 0.5269 - val_loss: 0.9265 - val_accuracy: 0.5377\n",
      "Epoch 9/10\n",
      "6850/6850 [==============================] - 2s 291us/step - loss: 0.9251 - accuracy: 0.5350 - val_loss: 0.9305 - val_accuracy: 0.5423\n",
      "Epoch 10/10\n",
      "6850/6850 [==============================] - 2s 298us/step - loss: 0.9217 - accuracy: 0.5342 - val_loss: 0.9207 - val_accuracy: 0.5394\n",
      "2141/2141 [==============================] - 0s 99us/step\n",
      "test loss: 0.9281109408873478\n",
      "test accuracy: 0.5333955883979797\n"
     ]
    }
   ],
   "source": [
    "lbl_train2 = y_train2\n",
    "lbl_test2 = y_test2\n",
    "#DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding \n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=3, kernel_initializer='normal', activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=512, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1024, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# Add output layer\n",
    "model.add(Dense(units=3, kernel_initializer='normal', activation='softmax'))\n",
    "print(model.summary())\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "y_train2 = np_utils.to_categorical(y_train2) \n",
    "y_test2 = np_utils.to_categorical(y_test2)\n",
    "\n",
    "model.fit(x=X_train2, y=y_train2, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "scores = model.evaluate(X_test2, y_test2)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[562 190  48]\n",
      " [349 279 161]\n",
      " [ 85 166 301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.70      0.63       800\n",
      "           1       0.44      0.35      0.39       789\n",
      "           2       0.59      0.55      0.57       552\n",
      "\n",
      "    accuracy                           0.53      2141\n",
      "   macro avg       0.53      0.53      0.53      2141\n",
      "weighted avg       0.52      0.53      0.52      2141\n",
      "\n",
      "after PCA on DNN\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "y_pred2 = model.predict_classes(X_test2)\n",
    "print(confusion_matrix(lbl_test2,y_pred2))\n",
    "print(classification_report(lbl_test2,y_pred2))\n",
    "print('after PCA on DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[596 173  31]\n",
      " [398 282 109]\n",
      " [104 217 231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.63       800\n",
      "           1       0.42      0.36      0.39       789\n",
      "           2       0.62      0.42      0.50       552\n",
      "\n",
      "    accuracy                           0.52      2141\n",
      "   macro avg       0.53      0.51      0.50      2141\n",
      "weighted avg       0.52      0.52      0.51      2141\n",
      "\n",
      "after NMF on SVM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=3, solver=\"cd\")\n",
    "\n",
    "newX2 = nmf.fit_transform(X)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(newX2, y, test_size=0.2, random_state=42)\n",
    "\n",
    "SVM.fit(X_train3, y_train3)\n",
    "y_pred3 = SVM.predict(X_test3)\n",
    "\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3,y_pred3))\n",
    "print('after NMF on SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[576  73 151]\n",
      " [388 100 301]\n",
      " [101  61 390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.72      0.62       800\n",
      "           1       0.43      0.13      0.20       789\n",
      "           2       0.46      0.71      0.56       552\n",
      "\n",
      "    accuracy                           0.50      2141\n",
      "   macro avg       0.48      0.52      0.46      2141\n",
      "weighted avg       0.48      0.50      0.45      2141\n",
      "\n",
      "after NMF on NB\n"
     ]
    }
   ],
   "source": [
    "clf_gnb.fit(X_train3, y_train3)\n",
    "y_pred3 = clf_gnb.predict(X_test3)\n",
    "\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3,y_pred3))\n",
    "print('after NMF on NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573 193  34]\n",
      " [326 338 125]\n",
      " [ 83 154 315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.72      0.64       800\n",
      "           1       0.49      0.43      0.46       789\n",
      "           2       0.66      0.57      0.61       552\n",
      "\n",
      "    accuracy                           0.57      2141\n",
      "   macro avg       0.58      0.57      0.57      2141\n",
      "weighted avg       0.57      0.57      0.57      2141\n",
      "\n",
      "after NMF on D-tree\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(X_train3, y_train3)\n",
    "y_pred3 = dtree.predict(X_test3)\n",
    "\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3,y_pred3))\n",
    "print('after NMF on D-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[566 196  38]\n",
      " [305 349 135]\n",
      " [ 73 158 321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       800\n",
      "           1       0.50      0.44      0.47       789\n",
      "           2       0.65      0.58      0.61       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.57      0.58      0.57      2141\n",
      "\n",
      "after NMF Random Forest\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train3, y_train3)\n",
    "y_pred3 = rf.predict(X_test3)\n",
    "\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3,y_pred3))\n",
    "print('after NMF Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[581 182  37]\n",
      " [314 342 133]\n",
      " [ 75 157 320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66       800\n",
      "           1       0.50      0.43      0.47       789\n",
      "           2       0.65      0.58      0.61       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.58      0.58      0.58      2141\n",
      "\n",
      "after NMF on XGBoost\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train3, y_train3)\n",
    "y_pred3 = xgb.predict(X_test3)\n",
    "\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3,y_pred3))\n",
    "print('after NMF on XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 660,995\n",
      "Trainable params: 660,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6850 samples, validate on 1713 samples\n",
      "Epoch 1/10\n",
      "6850/6850 [==============================] - 2s 343us/step - loss: 0.9838 - accuracy: 0.4847 - val_loss: 0.9479 - val_accuracy: 0.5236\n",
      "Epoch 2/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9600 - accuracy: 0.5159 - val_loss: 0.9601 - val_accuracy: 0.5184\n",
      "Epoch 3/10\n",
      "6850/6850 [==============================] - 2s 284us/step - loss: 0.9689 - accuracy: 0.5034 - val_loss: 0.9430 - val_accuracy: 0.5254\n",
      "Epoch 4/10\n",
      "6850/6850 [==============================] - 2s 288us/step - loss: 0.9574 - accuracy: 0.5143 - val_loss: 0.9490 - val_accuracy: 0.5143\n",
      "Epoch 5/10\n",
      "6850/6850 [==============================] - 2s 280us/step - loss: 0.9575 - accuracy: 0.5168 - val_loss: 0.9623 - val_accuracy: 0.5155\n",
      "Epoch 6/10\n",
      "6850/6850 [==============================] - 2s 283us/step - loss: 0.9570 - accuracy: 0.5112 - val_loss: 0.9442 - val_accuracy: 0.5196\n",
      "Epoch 7/10\n",
      "6850/6850 [==============================] - 2s 281us/step - loss: 0.9584 - accuracy: 0.5130 - val_loss: 0.9408 - val_accuracy: 0.5231\n",
      "Epoch 8/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9584 - accuracy: 0.5104 - val_loss: 0.9476 - val_accuracy: 0.5236\n",
      "Epoch 9/10\n",
      "6850/6850 [==============================] - 2s 270us/step - loss: 0.9586 - accuracy: 0.5134 - val_loss: 0.9415 - val_accuracy: 0.5236\n",
      "Epoch 10/10\n",
      "6850/6850 [==============================] - 2s 271us/step - loss: 0.9531 - accuracy: 0.5165 - val_loss: 0.9412 - val_accuracy: 0.5201\n",
      "2141/2141 [==============================] - 0s 104us/step\n",
      "test loss: 0.9513959593162643\n",
      "test accuracy: 0.5105091333389282\n"
     ]
    }
   ],
   "source": [
    "lbl_train3 = y_train3\n",
    "lbl_test3 = y_test3\n",
    "#DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding \n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=3, kernel_initializer='normal', activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=512, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1024, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# Add output layer\n",
    "model.add(Dense(units=3, kernel_initializer='normal', activation='softmax'))\n",
    "print(model.summary())\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "y_train3 = np_utils.to_categorical(y_train3) \n",
    "y_test3 = np_utils.to_categorical(y_test3)\n",
    "\n",
    "model.fit(x=X_train3, y=y_train3, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "scores = model.evaluate(X_test3, y_test3)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[591 171  38]\n",
      " [399 275 115]\n",
      " [106 219 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.62       800\n",
      "           1       0.41      0.35      0.38       789\n",
      "           2       0.60      0.41      0.49       552\n",
      "\n",
      "    accuracy                           0.51      2141\n",
      "   macro avg       0.52      0.50      0.50      2141\n",
      "weighted avg       0.51      0.51      0.50      2141\n",
      "\n",
      "after NMF on DNN\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "y_pred3 = model.predict_classes(X_test3)\n",
    "print(confusion_matrix(lbl_test3,y_pred3))\n",
    "print(classification_report(lbl_test3,y_pred3))\n",
    "print('after NMF on DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[587 191  22]\n",
      " [397 301  91]\n",
      " [104 231 217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.73      0.62       800\n",
      "           1       0.42      0.38      0.40       789\n",
      "           2       0.66      0.39      0.49       552\n",
      "\n",
      "    accuracy                           0.52      2141\n",
      "   macro avg       0.54      0.50      0.50      2141\n",
      "weighted avg       0.52      0.52      0.51      2141\n",
      "\n",
      "after SVD on SVM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=3)\n",
    "\n",
    "newX3 = svd.fit_transform(X)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(newX3, y, test_size=0.2, random_state=42)\n",
    "\n",
    "SVM.fit(X_train4, y_train4)\n",
    "y_pred4 = SVM.predict(X_test4)\n",
    "\n",
    "print(confusion_matrix(y_test4,y_pred4))\n",
    "print(classification_report(y_test4,y_pred4))\n",
    "print('after SVD on SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573 172  55]\n",
      " [383 249 157]\n",
      " [100 185 267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.72      0.62       800\n",
      "           1       0.41      0.32      0.36       789\n",
      "           2       0.56      0.48      0.52       552\n",
      "\n",
      "    accuracy                           0.51      2141\n",
      "   macro avg       0.50      0.51      0.50      2141\n",
      "weighted avg       0.50      0.51      0.50      2141\n",
      "\n",
      "after SVD on NB\n"
     ]
    }
   ],
   "source": [
    "clf_gnb.fit(X_train4, y_train4)\n",
    "y_pred4 = clf_gnb.predict(X_test4)\n",
    "\n",
    "print(confusion_matrix(y_test4,y_pred4))\n",
    "print(classification_report(y_test4,y_pred4))\n",
    "print('after SVD on NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[577 189  34]\n",
      " [321 340 128]\n",
      " [ 85 153 314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65       800\n",
      "           1       0.50      0.43      0.46       789\n",
      "           2       0.66      0.57      0.61       552\n",
      "\n",
      "    accuracy                           0.57      2141\n",
      "   macro avg       0.58      0.57      0.57      2141\n",
      "weighted avg       0.57      0.57      0.57      2141\n",
      "\n",
      "after SVD on D-tree\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(X_train4, y_train4)\n",
    "y_pred4 = dtree.predict(X_test4)\n",
    "\n",
    "print(confusion_matrix(y_test4,y_pred4))\n",
    "print(classification_report(y_test4,y_pred4))\n",
    "print('after SVD on D-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570 194  36]\n",
      " [297 351 141]\n",
      " [ 77 145 330]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       800\n",
      "           1       0.51      0.44      0.47       789\n",
      "           2       0.65      0.60      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.59      0.59      0.58      2141\n",
      "weighted avg       0.58      0.58      0.58      2141\n",
      "\n",
      "after SVD on Random Forest\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train4, y_train4)\n",
    "y_pred4 = rf.predict(X_test4)\n",
    "\n",
    "print(confusion_matrix(y_test4,y_pred4))\n",
    "print(classification_report(y_test4,y_pred4))\n",
    "print('after SVD on Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570 194  36]\n",
      " [301 350 138]\n",
      " [ 76 151 325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       800\n",
      "           1       0.50      0.44      0.47       789\n",
      "           2       0.65      0.59      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.59      0.58      0.58      2141\n",
      "weighted avg       0.58      0.58      0.58      2141\n",
      "\n",
      "after SVD on XGBoost\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train4, y_train4)\n",
    "y_pred4 = xgb.predict(X_test4)\n",
    "\n",
    "print(confusion_matrix(y_test4,y_pred4))\n",
    "print(classification_report(y_test4,y_pred4))\n",
    "print('after SVD on XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 660,995\n",
      "Trainable params: 660,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6850 samples, validate on 1713 samples\n",
      "Epoch 1/10\n",
      "6850/6850 [==============================] - 2s 363us/step - loss: 0.9770 - accuracy: 0.5038 - val_loss: 0.9554 - val_accuracy: 0.5178\n",
      "Epoch 2/10\n",
      "6850/6850 [==============================] - 2s 287us/step - loss: 0.9598 - accuracy: 0.5120 - val_loss: 0.9429 - val_accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "6850/6850 [==============================] - 2s 298us/step - loss: 0.9554 - accuracy: 0.5134 - val_loss: 0.9455 - val_accuracy: 0.5190\n",
      "Epoch 4/10\n",
      "6850/6850 [==============================] - 2s 294us/step - loss: 0.9557 - accuracy: 0.5092 - val_loss: 0.9420 - val_accuracy: 0.5242\n",
      "Epoch 5/10\n",
      "6850/6850 [==============================] - 2s 298us/step - loss: 0.9511 - accuracy: 0.5092 - val_loss: 0.9463 - val_accuracy: 0.5166\n",
      "Epoch 6/10\n",
      "6850/6850 [==============================] - 2s 299us/step - loss: 0.9463 - accuracy: 0.5193 - val_loss: 0.9419 - val_accuracy: 0.5190\n",
      "Epoch 7/10\n",
      "6850/6850 [==============================] - 2s 297us/step - loss: 0.9459 - accuracy: 0.5128 - val_loss: 0.9428 - val_accuracy: 0.5283\n",
      "Epoch 8/10\n",
      "6850/6850 [==============================] - 2s 298us/step - loss: 0.9464 - accuracy: 0.5190 - val_loss: 0.9442 - val_accuracy: 0.5201\n",
      "Epoch 9/10\n",
      "6850/6850 [==============================] - 2s 299us/step - loss: 0.9429 - accuracy: 0.5212 - val_loss: 0.9473 - val_accuracy: 0.5260\n",
      "Epoch 10/10\n",
      "6850/6850 [==============================] - 2s 296us/step - loss: 0.9390 - accuracy: 0.5209 - val_loss: 0.9437 - val_accuracy: 0.5283\n",
      "2141/2141 [==============================] - 0s 99us/step\n",
      "test loss: 0.9469115843231686\n",
      "test accuracy: 0.5142456889152527\n"
     ]
    }
   ],
   "source": [
    "lbl_train4 = y_train4\n",
    "lbl_test4 = y_test4\n",
    "#DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding \n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=3, kernel_initializer='normal', activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=512, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1024, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# Add output layer\n",
    "model.add(Dense(units=3, kernel_initializer='normal', activation='softmax'))\n",
    "print(model.summary())\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "y_train4 = np_utils.to_categorical(y_train4) \n",
    "y_test4 = np_utils.to_categorical(y_test4)\n",
    "\n",
    "model.fit(x=X_train4, y=y_train4, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "scores = model.evaluate(X_test4, y_test4)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627 149  24]\n",
      " [438 262  89]\n",
      " [150 190 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.78      0.62       800\n",
      "           1       0.44      0.33      0.38       789\n",
      "           2       0.65      0.38      0.48       552\n",
      "\n",
      "    accuracy                           0.51      2141\n",
      "   macro avg       0.53      0.50      0.49      2141\n",
      "weighted avg       0.52      0.51      0.50      2141\n",
      "\n",
      "after SVD on DNN\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "y_pred4 = model.predict_classes(X_test4)\n",
    "print(confusion_matrix(lbl_test4,y_pred4))\n",
    "print(classification_report(lbl_test4,y_pred4))\n",
    "print('after SVD on DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 6)                 24        \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10704/10704 [==============================] - 1s 81us/step - loss: 6.7101 - accuracy: 0.0289\n",
      "Epoch 2/10\n",
      "10704/10704 [==============================] - 1s 69us/step - loss: 5.1829 - accuracy: 0.0288\n",
      "Epoch 3/10\n",
      "10704/10704 [==============================] - 1s 68us/step - loss: 4.6017 - accuracy: 0.0143\n",
      "Epoch 4/10\n",
      "10704/10704 [==============================] - 1s 70us/step - loss: 4.0723 - accuracy: 0.0230\n",
      "Epoch 5/10\n",
      "10704/10704 [==============================] - 1s 67us/step - loss: 4.0682 - accuracy: 0.0231\n",
      "Epoch 6/10\n",
      "10704/10704 [==============================] - 1s 68us/step - loss: 4.3951 - accuracy: 0.0239\n",
      "Epoch 7/10\n",
      "10704/10704 [==============================] - 1s 70us/step - loss: 4.9535 - accuracy: 0.0263\n",
      "Epoch 8/10\n",
      "10704/10704 [==============================] - 1s 73us/step - loss: 6.1123 - accuracy: 0.0342\n",
      "Epoch 9/10\n",
      "10704/10704 [==============================] - 1s 72us/step - loss: 10.0116 - accuracy: 0.0220\n",
      "Epoch 10/10\n",
      "10704/10704 [==============================] - 1s 66us/step - loss: 11.2290 - accuracy: 0.0016\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "#X_train6 #(8563,6)\n",
    "#y_train6 #(8563,)\n",
    "\n",
    "input_dim = 6\n",
    "encoding_dim = 3\n",
    "# encoder layers\n",
    "input_data = Input(shape=(input_dim,))\n",
    "# encoder = Dense(input_dim, activation='tanh')(input_data)\n",
    "encoder_output = Dense(encoding_dim,activation='tanh')(input_data)\n",
    "\n",
    "# decoder layers\n",
    "# decoder = Dense(encoding_dim, activation='tanh')(encoder_output)\n",
    "decoder = Dense(input_dim, activation='tanh')(encoder_output)\n",
    "\n",
    "autoencoder = Model(inputs=input_data,outputs=decoder)\n",
    "encoder = Model(inputs=input_data, output=encoder_output)\n",
    "\n",
    "print(autoencoder.summary())\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = autoencoder.fit(X, X, epochs=10, verbose=1, batch_size=32, shuffle=True)\n",
    "AE_X = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[580 196  24]\n",
      " [370 305 114]\n",
      " [ 91 220 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63       800\n",
      "           1       0.42      0.39      0.40       789\n",
      "           2       0.64      0.44      0.52       552\n",
      "\n",
      "    accuracy                           0.53      2141\n",
      "   macro avg       0.54      0.52      0.52      2141\n",
      "weighted avg       0.53      0.53      0.52      2141\n",
      "\n",
      "after Autoencoder on SVM\n"
     ]
    }
   ],
   "source": [
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(AE_X, y, test_size=0.2, random_state=42)\n",
    "SVM.fit(X_train5, y_train5)\n",
    "y_pred5 = SVM.predict(X_test5)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred5))\n",
    "print(classification_report(y_test5,y_pred5))\n",
    "print('after Autoencoder on SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[473 142 185]\n",
      " [309 152 328]\n",
      " [ 92  66 394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.57       800\n",
      "           1       0.42      0.19      0.26       789\n",
      "           2       0.43      0.71      0.54       552\n",
      "\n",
      "    accuracy                           0.48      2141\n",
      "   macro avg       0.47      0.50      0.46      2141\n",
      "weighted avg       0.47      0.48      0.45      2141\n",
      "\n",
      "after Autoencoder on NB\n"
     ]
    }
   ],
   "source": [
    "clf_gnb.fit(X_train5, y_train5)\n",
    "y_pred5 = clf_gnb.predict(X_test5)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred5))\n",
    "print(classification_report(y_test5,y_pred5))\n",
    "print('after Autoencoder on NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[571 194  35]\n",
      " [327 335 127]\n",
      " [ 80 155 317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64       800\n",
      "           1       0.49      0.42      0.45       789\n",
      "           2       0.66      0.57      0.61       552\n",
      "\n",
      "    accuracy                           0.57      2141\n",
      "   macro avg       0.58      0.57      0.57      2141\n",
      "weighted avg       0.57      0.57      0.57      2141\n",
      "\n",
      "after Autoencoder on D-tree\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(X_train5, y_train5)\n",
    "y_pred5 = dtree.predict(X_test5)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred5))\n",
    "print(classification_report(y_test5,y_pred5))\n",
    "print('after Autoencoder on D-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[561 198  41]\n",
      " [308 342 139]\n",
      " [ 69 147 336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65       800\n",
      "           1       0.50      0.43      0.46       789\n",
      "           2       0.65      0.61      0.63       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.58      0.58      0.58      2141\n",
      "weighted avg       0.57      0.58      0.57      2141\n",
      "\n",
      "after Autoencoder on Random Forest\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train5, y_train5)\n",
    "y_pred5 = rf.predict(X_test5)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred5))\n",
    "print(classification_report(y_test5,y_pred5))\n",
    "print('after Autoencoder on Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569 199  32]\n",
      " [312 351 126]\n",
      " [ 72 164 316]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       800\n",
      "           1       0.49      0.44      0.47       789\n",
      "           2       0.67      0.57      0.62       552\n",
      "\n",
      "    accuracy                           0.58      2141\n",
      "   macro avg       0.59      0.58      0.58      2141\n",
      "weighted avg       0.58      0.58      0.57      2141\n",
      "\n",
      "after Autoencoder on XGBoost\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train5, y_train5)\n",
    "y_pred5 = xgb.predict(X_test5)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred5))\n",
    "print(classification_report(y_test5,y_pred5))\n",
    "print('after Autoencoder on XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 660,995\n",
      "Trainable params: 660,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6850 samples, validate on 1713 samples\n",
      "Epoch 1/10\n",
      "6850/6850 [==============================] - 2s 338us/step - loss: 0.9616 - accuracy: 0.5012 - val_loss: 0.9424 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9330 - accuracy: 0.5168 - val_loss: 0.9194 - val_accuracy: 0.5435\n",
      "Epoch 3/10\n",
      "6850/6850 [==============================] - 2s 274us/step - loss: 0.9309 - accuracy: 0.5168 - val_loss: 0.9160 - val_accuracy: 0.5464\n",
      "Epoch 4/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9278 - accuracy: 0.5190 - val_loss: 0.9203 - val_accuracy: 0.5388\n",
      "Epoch 5/10\n",
      "6850/6850 [==============================] - 2s 277us/step - loss: 0.9259 - accuracy: 0.5274 - val_loss: 0.9191 - val_accuracy: 0.5452\n",
      "Epoch 6/10\n",
      "6850/6850 [==============================] - 2s 281us/step - loss: 0.9240 - accuracy: 0.5239 - val_loss: 0.9239 - val_accuracy: 0.5470\n",
      "Epoch 7/10\n",
      "6850/6850 [==============================] - 2s 282us/step - loss: 0.9227 - accuracy: 0.5269 - val_loss: 0.9275 - val_accuracy: 0.5546\n",
      "Epoch 8/10\n",
      "6850/6850 [==============================] - 2s 286us/step - loss: 0.9248 - accuracy: 0.5258 - val_loss: 0.9154 - val_accuracy: 0.5447\n",
      "Epoch 9/10\n",
      "6850/6850 [==============================] - 2s 279us/step - loss: 0.9210 - accuracy: 0.5292 - val_loss: 0.9158 - val_accuracy: 0.5511\n",
      "Epoch 10/10\n",
      "6850/6850 [==============================] - 2s 276us/step - loss: 0.9197 - accuracy: 0.5285 - val_loss: 0.9159 - val_accuracy: 0.5476\n",
      "2141/2141 [==============================] - 0s 104us/step\n",
      "test loss: 0.9233719089330774\n",
      "test accuracy: 0.5217188000679016\n"
     ]
    }
   ],
   "source": [
    "lbl_train5 = y_train5\n",
    "lbl_test5 = y_test5\n",
    "#DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding \n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=3, kernel_initializer='normal', activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=512, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1024, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# Add output layer\n",
    "model.add(Dense(units=3, kernel_initializer='normal', activation='softmax'))\n",
    "print(model.summary())\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "y_train5 = np_utils.to_categorical(y_train5) \n",
    "y_test5 = np_utils.to_categorical(y_test5)\n",
    "\n",
    "model.fit(x=X_train5, y=y_train5, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "scores = model.evaluate(X_test5, y_test5)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[599 121  80]\n",
      " [400 200 189]\n",
      " [106 128 318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.75      0.63       800\n",
      "           1       0.45      0.25      0.32       789\n",
      "           2       0.54      0.58      0.56       552\n",
      "\n",
      "    accuracy                           0.52      2141\n",
      "   macro avg       0.51      0.53      0.50      2141\n",
      "weighted avg       0.51      0.52      0.50      2141\n",
      "\n",
      "after Autoencoder on DNN\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "y_pred5 = model.predict_classes(X_test5)\n",
    "print(confusion_matrix(lbl_test5,y_pred5))\n",
    "print(classification_report(lbl_test5,y_pred5))\n",
    "print('after Autoencoder on DNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
